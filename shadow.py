from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
import sounddevice as sd
import numpy as np
import torch
import os

# Magyar besz√©dgener√°l√°s
def speak(text):
    print(f"Shadow: {text}")
    os.system(f'espeak-ng -v hu "{text}"')

# Modell bet√∂lt√©se (els≈ë ind√≠t√°sn√°l let√∂lt)
print("üì¶ Modell bet√∂lt√©se...")
processor = Wav2Vec2Processor.from_pretrained("jonatasgrosman/wav2vec2-large-xlsr-53-hungarian")
model = Wav2Vec2ForCTC.from_pretrained("jonatasgrosman/wav2vec2-large-xlsr-53-hungarian")

# Hang r√∂gz√≠t√©se
def record_audio(duration=5, samplerate=16000):
    print("üé§ Besz√©lj most...")
    audio = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='float32')
    sd.wait()
    return np.squeeze(audio)

# Felismer√©s
def transcribe(audio, samplerate=16000):
    inputs = processor(audio, sampling_rate=samplerate, return_tensors="pt", padding=True)
    with torch.no_grad():
        logits = model(**inputs).logits
    predicted_ids = torch.argmax(logits, dim=-1)
    transcription = processor.batch_decode(predicted_ids)[0]
    return transcription.lower()

# Parancs feldolgoz√°s
def process_command(text):
    if "hogy vagy" in text:
        return "J√≥l vagyok, f≈ën√∂k."
    elif "mennyi az id≈ë" in text or "h√°ny √≥ra" in text:
        from datetime import datetime
        now = datetime.now().strftime("%H:%M")
        return f"Most {now} van."
    elif "kil√©p√©s" in text:
        speak("Viszl√°t f≈ën√∂k.")
        exit()
    else:
        return "Ezt m√©g nem tudom."

# F≈ë program
def main():
    speak("Shadow k√©szen √°ll.")
    while True:
        audio = record_audio()
        text = transcribe(audio)
        print("üß† Felismert sz√∂veg:", text)
        if text:
            response = process_command(text)
            speak(response)

if __name__ == "__main__":
    main()